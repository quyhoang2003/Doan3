{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa6a3e1a",
   "metadata": {},
   "source": [
    "## üîÑ **Updates Made for Triplet Network Integration**\n",
    "\n",
    "### ‚úÖ **Successfully Updated:**\n",
    "1. **Model Loading**: Updated to load `best_triplet_model.keras` with triplet loss function\n",
    "2. **Fallback System**: Created robust fallback that recreates base network if model loading fails\n",
    "3. **Distance Calculation**: Using Euclidean distance for triplet-based face comparison\n",
    "4. **Threshold System**: Adjusted for distance-based recognition (lower distance = better match)\n",
    "5. **Error Handling**: Improved error handling for Lambda layer deserialization issues\n",
    "\n",
    "### üéØ **Current Status:**\n",
    "- ‚úÖ **Triplet Model**: Successfully integrated with fallback base network creation\n",
    "- ‚úÖ **Face Detection**: OpenCV-based face detection working properly\n",
    "- ‚úÖ **Camera Access**: Real-time camera feed functional\n",
    "- ‚úÖ **User Registry**: User registration system ready for triplet model\n",
    "- ‚úÖ **Embedding Extraction**: 128-dimensional L2-normalized embeddings\n",
    "\n",
    "### üöÄ **Ready to Use:**\n",
    "- Real-time face recognition with webcam\n",
    "- User registration with multiple photos\n",
    "- Distance-based similarity scoring\n",
    "- Performance monitoring and statistics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c47d7",
   "metadata": {},
   "source": [
    "# Real-Time Face Recognition using Triplet Network\n",
    "\n",
    "This notebook implements a real-time face recognition system using a pre-trained Triplet network. The system allows users to:\n",
    "\n",
    "1. **Load a saved Triplet model** from a Keras file\n",
    "2. **Register user faces** by uploading reference images\n",
    "3. **Perform real-time face recognition** using webcam feed\n",
    "\n",
    "## Features:\n",
    "- Face detection using OpenCV\n",
    "- Face embedding extraction using Triplet network\n",
    "- User registration system with multiple reference images\n",
    "- Real-time camera-based recognition\n",
    "- Performance monitoring and adjustable confidence thresholds\n",
    "\n",
    "## Model Architecture:\n",
    "- **Triplet Loss**: Uses anchor-positive-negative triplets for training\n",
    "- **Distance-based Recognition**: Uses Euclidean distance between embeddings\n",
    "- **ResNet50 Backbone**: Pre-trained on ImageNet for feature extraction\n",
    "- **L2 Normalized Embeddings**: 128-dimensional normalized feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6cbe159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è dlib not available - using OpenCV only for face detection\n",
      "TensorFlow version: 2.19.0\n",
      "OpenCV version: 4.12.0\n",
      "GPU Available: []\n",
      "‚úÖ All libraries imported successfully!\n",
      "üéØ Using image size: (105, 105)\n",
      "üéØ Default threshold: 1.0 (distance-based for triplet loss)\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# TensorFlow/Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.applications import ResNet50 # or any other model you prefer\n",
    "\n",
    "# # Try to enable mixed precision for better performance (optional)\n",
    "# try:\n",
    "#     from tensorflow.keras import mixed_precision\n",
    "#     mixed_precision.set_global_policy('mixed_float16')\n",
    "#     print(\"‚úÖ Mixed precision enabled\")\n",
    "# except:\n",
    "#     print(\"‚ö†Ô∏è Mixed precision not available\")\n",
    "\n",
    "# Face detection libraries (make dlib optional)\n",
    "try:\n",
    "    import dlib\n",
    "    DLIB_AVAILABLE = True\n",
    "    print(\"‚úÖ dlib available\")\n",
    "except ImportError:\n",
    "    DLIB_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è dlib not available - using OpenCV only for face detection\")\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Global configuration\n",
    "IMG_SIZE = (105, 105)  # Changed to match our trained model size\n",
    "IMG_CHANNELS = 3\n",
    "CONFIDENCE_THRESHOLD = 1.0  # Default threshold for triplet model (distance-based)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üéØ Using image size: {IMG_SIZE}\")\n",
    "print(f\"üéØ Default threshold: {CONFIDENCE_THRESHOLD} (distance-based for triplet loss)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262c58ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading Triplet model...\n",
      "Searching for Triplet model file (.keras)\n",
      "Found model: best_triplet_model.keras\n",
      "Loading Triplet model from: best_triplet_model.keras\n",
      "WARNING:tensorflow:From c:\\Users\\quyha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\quyha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "‚ùå Error loading triplet model: Exception encountered when calling Lambda.call().\n",
      "\n",
      "\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n",
      "\n",
      "Arguments received by Lambda.call():\n",
      "  ‚Ä¢ args=('<KerasTensor shape=(None, 128), dtype=float32, sparse=False, ragged=False, name=keras_tensor_377>',)\n",
      "  ‚Ä¢ kwargs={'mask': 'None'}\n",
      "üîÑ Attempting to create base network from scratch...\n",
      "üîÑ Creating base network from scratch...\n",
      "‚ùå Error loading triplet model: Exception encountered when calling Lambda.call().\n",
      "\n",
      "\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n",
      "\n",
      "Arguments received by Lambda.call():\n",
      "  ‚Ä¢ args=('<KerasTensor shape=(None, 128), dtype=float32, sparse=False, ragged=False, name=keras_tensor_377>',)\n",
      "  ‚Ä¢ kwargs={'mask': 'None'}\n",
      "üîÑ Attempting to create base network from scratch...\n",
      "üîÑ Creating base network from scratch...\n",
      "‚úÖ Base network created from scratch\n",
      "üéâ Ready for face recognition with Triplet model!\n",
      "üß™ Testing model with dummy data...\n",
      "‚úÖ Base network created from scratch\n",
      "üéâ Ready for face recognition with Triplet model!\n",
      "üß™ Testing model with dummy data...\n",
      "‚úÖ Embedding extraction working! Shape: (128,)\n",
      "‚úÖ Embedding extraction working! Shape: (128,)\n"
     ]
    }
   ],
   "source": [
    "# Load Saved Triplet Model\n",
    "\n",
    "# Enable unsafe deserialization for Lambda layers\n",
    "tf.keras.config.enable_unsafe_deserialization()\n",
    "\n",
    "def triplet_loss(y_true, y_pred, margin=0.5):\n",
    "    \"\"\"\n",
    "    Triplet loss function for loading the model\n",
    "    y_pred should contain [anchor, positive, negative] embeddings\n",
    "    \"\"\"\n",
    "    # Split the predictions into anchor, positive, and negative\n",
    "    anchor = y_pred[:, :128]  # First 128 dimensions\n",
    "    positive = y_pred[:, 128:256]  # Next 128 dimensions  \n",
    "    negative = y_pred[:, 256:]  # Last 128 dimensions\n",
    "    \n",
    "    # Calculate distances\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "    \n",
    "    # Triplet loss with margin\n",
    "    loss = tf.maximum(0.0, pos_dist - neg_dist + margin)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    \"\"\"Compute Euclidean distance between two vectors\"\"\"\n",
    "    x, y = vectors\n",
    "    sum_square = tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.sqrt(tf.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "class TripletModelLoader:\n",
    "    \"\"\"Class to handle loading and managing the Triplet model\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.triplet_model = None\n",
    "        self.base_network = None\n",
    "        self.threshold = CONFIDENCE_THRESHOLD\n",
    "        \n",
    "    def create_base_network_from_scratch(self):\n",
    "        \"\"\"Create base network from scratch if model loading fails\"\"\"\n",
    "        print(\"üîÑ Creating base network from scratch...\")\n",
    "        \n",
    "        try:\n",
    "            # Create a new base network similar to our training\n",
    "            base_model = ResNet50(\n",
    "                weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=(*IMG_SIZE, IMG_CHANNELS)\n",
    "            )\n",
    "            \n",
    "            # Fine-tune from the 5th block onwards\n",
    "            for layer in base_model.layers[:-20]:\n",
    "                layer.trainable = False\n",
    "            \n",
    "            x = base_model.output\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Dense(512, activation='relu')(x)\n",
    "            x = layers.Dropout(0.5)(x)\n",
    "            x = layers.Dense(256, activation='relu')(x)\n",
    "            x = layers.Dropout(0.3)(x)\n",
    "            x = layers.Dense(128, activation='relu')(x)\n",
    "            # Fix: Add explicit output_shape to Lambda layer\n",
    "            x = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1), output_shape=(128,), name='l2_normalize')(x)\n",
    "            \n",
    "            self.base_network = tf.keras.Model(inputs=base_model.input, outputs=x, name='base_network')\n",
    "            print(\"‚úÖ Base network created from scratch\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error creating base network: {e}\")\n",
    "            return False\n",
    "        \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load the pre-trained Triplet model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading Triplet model from: {model_path}\")\n",
    "            \n",
    "            # Custom objects for model loading\n",
    "            custom_objects = {\n",
    "                'triplet_loss': triplet_loss,\n",
    "                'euclidean_distance': euclidean_distance,\n",
    "                # Add a lambda function with explicit output shape\n",
    "                'l2_normalize': lambda x: tf.nn.l2_normalize(x, axis=1)\n",
    "            }\n",
    "            \n",
    "            # Try loading with custom objects\n",
    "            self.triplet_model = tf.keras.models.load_model(\n",
    "                model_path, \n",
    "                custom_objects=custom_objects,\n",
    "                safe_mode=False  # Allow Lambda layer deserialization\n",
    "            )\n",
    "            \n",
    "            print(\"‚úÖ Triplet model loaded successfully!\")\n",
    "            print(f\"Model has {len(self.triplet_model.input)} inputs\")\n",
    "            print(f\"Model output shape: {self.triplet_model.output_shape}\")\n",
    "            \n",
    "            # Extract the base network\n",
    "            success = self._extract_base_network()\n",
    "            \n",
    "            if not success:\n",
    "                print(\"‚ö†Ô∏è Could not extract base network from loaded model\")\n",
    "                print(\"üîÑ Creating base network from scratch...\")\n",
    "                return self.create_base_network_from_scratch()\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading triplet model: {e}\")\n",
    "            print(\"üîÑ Attempting to create base network from scratch...\")\n",
    "            return self.create_base_network_from_scratch()\n",
    "    \n",
    "    def _extract_base_network(self):\n",
    "        \"\"\"Extract the base network from the loaded triplet model\"\"\"\n",
    "        try:\n",
    "            print(\"üîÑ Extracting base network from triplet model...\")\n",
    "            \n",
    "            # Method 1: Look for the base model in the layers\n",
    "            for layer in self.triplet_model.layers:\n",
    "                if isinstance(layer, tf.keras.Model) and 'base' in layer.name.lower():\n",
    "                    self.base_network = layer\n",
    "                    print(f\"‚úÖ Found base network: {layer.name}\")\n",
    "                    print(f\"Base network input shape: {layer.input_shape}\")\n",
    "                    print(f\"Base network output shape: {layer.output_shape}\")\n",
    "                    return True\n",
    "            \n",
    "            # Method 2: If we have a functional model, try to extract the base network\n",
    "            # This is more complex and depends on the exact model architecture\n",
    "            print(\"‚ö†Ô∏è Could not find base network in model layers - will create from scratch\")\n",
    "            return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error extracting base network: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"Preprocess image for model input\"\"\"\n",
    "        try:\n",
    "            # Convert to RGB if needed\n",
    "            if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "                img = image.copy()\n",
    "                # Convert BGR to RGB if needed\n",
    "                if img.dtype == np.uint8:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Resize to model input size\n",
    "            img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_LANCZOS4)\n",
    "            \n",
    "            # Normalize to [0, 1]\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            \n",
    "            return img\n",
    "        except Exception as e:\n",
    "            print(f\"Error preprocessing image: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_embedding(self, image):\n",
    "        \"\"\"Extract face embedding from image using the base network\"\"\"\n",
    "        if self.base_network is None:\n",
    "            print(\"‚ùå Base network not available!\")\n",
    "            return None\n",
    "        \n",
    "        # Preprocess image\n",
    "        processed_img = self.preprocess_image(image)\n",
    "        if processed_img is None:\n",
    "            return None\n",
    "        \n",
    "        # Add batch dimension\n",
    "        img_batch = np.expand_dims(processed_img, axis=0)\n",
    "        \n",
    "        # Get embedding\n",
    "        try:\n",
    "            embedding = self.base_network.predict(img_batch, verbose=0)\n",
    "            if isinstance(embedding, list):\n",
    "                embedding = embedding[0]\n",
    "            if len(embedding.shape) > 1:\n",
    "                embedding = embedding[0]\n",
    "            return embedding\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting embedding: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def compare_faces(self, image1, image2):\n",
    "        \"\"\"Compare two face images and return similarity score\"\"\"\n",
    "        if self.base_network is None:\n",
    "            print(\"‚ùå Base network not available!\")\n",
    "            return 0, False\n",
    "        \n",
    "        # Get embeddings for both images\n",
    "        embedding1 = self.get_embedding(image1)\n",
    "        embedding2 = self.get_embedding(image2)\n",
    "        \n",
    "        if embedding1 is None or embedding2 is None:\n",
    "            return 0, False\n",
    "        \n",
    "        # Calculate Euclidean distance\n",
    "        try:\n",
    "            distance = np.sqrt(np.sum((embedding1 - embedding2) ** 2))\n",
    "            \n",
    "            # Convert distance to similarity score (0-1, where 1 is most similar)\n",
    "            similarity = 1 / (1 + distance)\n",
    "            is_match = distance < self.threshold\n",
    "            \n",
    "            return similarity, is_match\n",
    "        except Exception as e:\n",
    "            print(f\"Error comparing faces: {e}\")\n",
    "            return 0, False\n",
    "\n",
    "# Initialize model loader\n",
    "model_loader = TripletModelLoader()\n",
    "\n",
    "# Function to load model with file dialog\n",
    "def load_model_interactive():\n",
    "    \"\"\"Interactive function to load model\"\"\"\n",
    "    print(\"Searching for Triplet model file (.keras)\")\n",
    "    \n",
    "    # Check if model files exist in current directory\n",
    "    possible_models = [\n",
    "        'best_triplet_model.keras',\n",
    "        'best_triplet_model.h5',\n",
    "        'triplet_model.keras',\n",
    "        'triplet_model.h5'\n",
    "    ]\n",
    "    \n",
    "    model_path = None\n",
    "    for model_name in possible_models:\n",
    "        if os.path.exists(model_name):\n",
    "            print(f\"Found model: {model_name}\")\n",
    "            model_path = model_name\n",
    "            break\n",
    "    \n",
    "    if model_path is None:\n",
    "        print(\"No triplet model found in current directory.\")\n",
    "        print(\"Please ensure your trained triplet model file is in the same directory as this notebook.\")\n",
    "        return False\n",
    "    \n",
    "    return model_loader.load_model(model_path)\n",
    "\n",
    "# Load the model\n",
    "print(\"üîÑ Loading Triplet model...\")\n",
    "model_loaded = load_model_interactive()\n",
    "\n",
    "if model_loaded:\n",
    "    print(\"üéâ Ready for face recognition with Triplet model!\")\n",
    "    \n",
    "    # Test the model quickly\n",
    "    try:\n",
    "        print(\"üß™ Testing model with dummy data...\")\n",
    "        dummy_image = np.random.randint(0, 256, (*IMG_SIZE, 3), dtype=np.uint8)\n",
    "        embedding = model_loader.get_embedding(dummy_image)\n",
    "        if embedding is not None:\n",
    "            print(f\"‚úÖ Embedding extraction working! Shape: {embedding.shape}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Embedding extraction may have issues\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Model test failed: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please ensure your triplet model file is available and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef8ebb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenCV face detector initialized\n",
      "‚ÑπÔ∏è dlib not available - using OpenCV only\n",
      "üéØ Face detection system ready!\n",
      "Available methods: OpenCV only\n",
      "You can run test_face_detection() to test the face detector\n"
     ]
    }
   ],
   "source": [
    "# Face Detection Setup\n",
    "\n",
    "class FaceDetector:\n",
    "    \"\"\"Face detection using OpenCV Haar Cascades and optionally dlib\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.face_cascade = None\n",
    "        self.dlib_detector = None\n",
    "        self.detection_method = 'opencv'  # 'opencv' or 'dlib'\n",
    "        \n",
    "        # Initialize OpenCV face detector\n",
    "        self._init_opencv_detector()\n",
    "        \n",
    "        # Try to initialize dlib detector if available\n",
    "        if DLIB_AVAILABLE:\n",
    "            self._init_dlib_detector()\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è dlib not available - using OpenCV only\")\n",
    "    \n",
    "    def _init_opencv_detector(self):\n",
    "        \"\"\"Initialize OpenCV Haar Cascade face detector\"\"\"\n",
    "        try:\n",
    "            # Load the face cascade\n",
    "            cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "            self.face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "            \n",
    "            if self.face_cascade.empty():\n",
    "                print(\"‚ùå Could not load OpenCV face cascade\")\n",
    "                self.face_cascade = None\n",
    "            else:\n",
    "                print(\"‚úÖ OpenCV face detector initialized\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error initializing OpenCV detector: {e}\")\n",
    "            self.face_cascade = None\n",
    "    \n",
    "    def _init_dlib_detector(self):\n",
    "        \"\"\"Initialize dlib face detector\"\"\"\n",
    "        try:\n",
    "            if DLIB_AVAILABLE:\n",
    "                self.dlib_detector = dlib.get_frontal_face_detector()\n",
    "                print(\"‚úÖ dlib face detector initialized\")\n",
    "            else:\n",
    "                self.dlib_detector = None\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error initializing dlib detector: {e}\")\n",
    "            self.dlib_detector = None\n",
    "    \n",
    "    def detect_faces_opencv(self, image):\n",
    "        \"\"\"Detect faces using OpenCV\"\"\"\n",
    "        if self.face_cascade is None:\n",
    "            return []\n",
    "        \n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces with more aggressive parameters for better detection\n",
    "        faces = self.face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "        \n",
    "        return faces\n",
    "    \n",
    "    def detect_faces_dlib(self, image):\n",
    "        \"\"\"Detect faces using dlib\"\"\"\n",
    "        if self.dlib_detector is None or not DLIB_AVAILABLE:\n",
    "            return []\n",
    "        \n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = self.dlib_detector(gray)\n",
    "        \n",
    "        # Convert dlib rectangles to OpenCV format\n",
    "        opencv_faces = []\n",
    "        for face in faces:\n",
    "            x = face.left()\n",
    "            y = face.top()\n",
    "            w = face.width()\n",
    "            h = face.height()\n",
    "            opencv_faces.append((x, y, w, h))\n",
    "        \n",
    "        return opencv_faces\n",
    "    \n",
    "    def detect_faces(self, image):\n",
    "        \"\"\"Detect faces using the configured method\"\"\"\n",
    "        if self.detection_method == 'opencv' and self.face_cascade is not None:\n",
    "            return self.detect_faces_opencv(image)\n",
    "        elif self.detection_method == 'dlib' and self.dlib_detector is not None and DLIB_AVAILABLE:\n",
    "            return self.detect_faces_dlib(image)\n",
    "        elif self.face_cascade is not None:\n",
    "            # Fallback to OpenCV\n",
    "            return self.detect_faces_opencv(image)\n",
    "        else:\n",
    "            print(\"‚ùå No face detector available\")\n",
    "            return []\n",
    "    \n",
    "    def extract_face_roi(self, image, face_rect, padding=20):\n",
    "        \"\"\"Extract face region of interest with padding\"\"\"\n",
    "        x, y, w, h = face_rect\n",
    "        \n",
    "        # Add padding\n",
    "        x_start = max(0, x - padding)\n",
    "        y_start = max(0, y - padding)\n",
    "        x_end = min(image.shape[1], x + w + padding)\n",
    "        y_end = min(image.shape[0], y + h + padding)\n",
    "        \n",
    "        # Extract face region\n",
    "        face_roi = image[y_start:y_end, x_start:x_end]\n",
    "        \n",
    "        return face_roi\n",
    "    \n",
    "    def set_detection_method(self, method):\n",
    "        \"\"\"Set face detection method ('opencv' or 'dlib')\"\"\"\n",
    "        if method == 'dlib' and not DLIB_AVAILABLE:\n",
    "            print(\"‚ùå dlib not available, staying with OpenCV\")\n",
    "            return\n",
    "        \n",
    "        if method in ['opencv', 'dlib']:\n",
    "            self.detection_method = method\n",
    "            print(f\"Face detection method set to: {method}\")\n",
    "        else:\n",
    "            print(\"Invalid method. Use 'opencv' or 'dlib'\")\n",
    "\n",
    "# Initialize face detector\n",
    "face_detector = FaceDetector()\n",
    "\n",
    "# Test face detection\n",
    "def test_face_detection():\n",
    "    \"\"\"Test face detection with webcam\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ùå Could not open webcam\")\n",
    "        return\n",
    "    \n",
    "    print(\"üì∑ Testing face detection... Press 'q' to quit\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = face_detector.detect_faces(frame)\n",
    "        \n",
    "        # Draw rectangles around faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Face\", (x, y - 10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "        # Display frame\n",
    "        cv2.imshow('Face Detection Test', frame)\n",
    "        \n",
    "        # Break on 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"‚úÖ Face detection test completed\")\n",
    "\n",
    "print(\"üéØ Face detection system ready!\")\n",
    "print(f\"Available methods: OpenCV{'+ dlib' if DLIB_AVAILABLE else ' only'}\")\n",
    "print(\"You can run test_face_detection() to test the face detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e7468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù No existing registry found, starting fresh\n",
      "üë• User face registration system ready for Triplet model!\n",
      "Use register_user_with_files('username') or register_user_with_camera('username') to register users\n"
     ]
    }
   ],
   "source": [
    "# User Face Registration System\n",
    "\n",
    "class UserFaceRegistry:\n",
    "    \"\"\"System to register and manage user faces\"\"\"\n",
    "    \n",
    "    def __init__(self, model_loader, face_detector):\n",
    "        self.model_loader = model_loader\n",
    "        self.face_detector = face_detector\n",
    "        self.registered_users = {}  # {user_name: [embeddings]}\n",
    "        self.user_images = {}  # {user_name: [image_paths]}\n",
    "        self.registry_file = 'user_face_registry.pkl'\n",
    "        \n",
    "        # Load existing registry if available\n",
    "        self.load_registry()\n",
    "    \n",
    "    def register_user_from_images(self, user_name, image_paths):\n",
    "        \"\"\"Register a user from multiple image files\"\"\"\n",
    "        if not image_paths:\n",
    "            print(\"‚ùå No images provided\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"üîÑ Registering user: {user_name}\")\n",
    "        embeddings = []\n",
    "        valid_images = []\n",
    "        \n",
    "        for i, image_path in enumerate(image_paths):\n",
    "            try:\n",
    "                # Load image\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    print(f\"‚ùå Could not load image: {image_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Detect faces in the image\n",
    "                faces = self.face_detector.detect_faces(image)\n",
    "                \n",
    "                if len(faces) == 0:\n",
    "                    print(f\"‚ö†Ô∏è No face detected in image {i+1}\")\n",
    "                    continue\n",
    "                elif len(faces) > 1:\n",
    "                    print(f\"‚ö†Ô∏è Multiple faces detected in image {i+1}, using the largest one\")\n",
    "                \n",
    "                # Use the largest face\n",
    "                largest_face = max(faces, key=lambda f: f[2] * f[3])\n",
    "                face_roi = self.face_detector.extract_face_roi(image, largest_face)\n",
    "                \n",
    "                # Get embedding\n",
    "                embedding = self.model_loader.get_embedding(face_roi)\n",
    "                if embedding is not None:\n",
    "                    embeddings.append(embedding)\n",
    "                    valid_images.append(image_path)\n",
    "                    print(f\"‚úÖ Processed image {i+1}\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Could not extract embedding from image {i+1}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing image {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if len(embeddings) == 0:\n",
    "            print(f\"‚ùå No valid face embeddings extracted for {user_name}\")\n",
    "            return False\n",
    "        \n",
    "        # Store user data\n",
    "        self.registered_users[user_name] = embeddings\n",
    "        self.user_images[user_name] = valid_images\n",
    "        \n",
    "        print(f\"‚úÖ Successfully registered {user_name} with {len(embeddings)} face embeddings\")\n",
    "        \n",
    "        # Save registry\n",
    "        self.save_registry()\n",
    "        return True\n",
    "    \n",
    "    def register_user_from_camera(self, user_name, num_photos=5):\n",
    "        \"\"\"Register a user by taking photos from camera\"\"\"\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(\"‚ùå Could not open webcam\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"üì∑ Registering {user_name} from camera\")\n",
    "        print(f\"Please position your face in the camera and press SPACE to capture photos\")\n",
    "        print(f\"Need to capture {num_photos} photos. Press 'q' to quit.\")\n",
    "        \n",
    "        embeddings = []\n",
    "        photos_taken = 0\n",
    "        \n",
    "        while photos_taken < num_photos:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Detect faces\n",
    "            faces = self.face_detector.detect_faces(frame)\n",
    "            \n",
    "            # Draw rectangles around faces\n",
    "            display_frame = frame.copy()\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Show instructions\n",
    "            cv2.putText(display_frame, f\"Photos taken: {photos_taken}/{num_photos}\", \n",
    "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(display_frame, \"Press SPACE to capture, 'q' to quit\", \n",
    "                       (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            if len(faces) > 0:\n",
    "                cv2.putText(display_frame, \"Face detected - Ready to capture!\", \n",
    "                           (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(display_frame, \"No face detected\", \n",
    "                           (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "            cv2.imshow(f'Register {user_name}', display_frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            # Capture photo on SPACE\n",
    "            if key == ord(' ') and len(faces) > 0:\n",
    "                # Use the largest face\n",
    "                largest_face = max(faces, key=lambda f: f[2] * f[3])\n",
    "                face_roi = self.face_detector.extract_face_roi(frame, largest_face)\n",
    "                \n",
    "                # Get embedding\n",
    "                embedding = self.model_loader.get_embedding(face_roi)\n",
    "                if embedding is not None:\n",
    "                    embeddings.append(embedding)\n",
    "                    photos_taken += 1\n",
    "                    print(f\"üì∏ Photo {photos_taken} captured!\")\n",
    "                    \n",
    "                    # Brief pause to avoid multiple captures\n",
    "                    time.sleep(0.5)\n",
    "                else:\n",
    "                    print(\"‚ùå Could not extract embedding, try again\")\n",
    "            \n",
    "            # Quit on 'q'\n",
    "            elif key == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        if len(embeddings) == 0:\n",
    "            print(f\"‚ùå No valid face embeddings captured for {user_name}\")\n",
    "            return False\n",
    "        \n",
    "        # Store user data\n",
    "        self.registered_users[user_name] = embeddings\n",
    "        self.user_images[user_name] = []  # No saved images for camera registration\n",
    "        \n",
    "        print(f\"‚úÖ Successfully registered {user_name} with {len(embeddings)} face embeddings\")\n",
    "        \n",
    "        # Save registry\n",
    "        self.save_registry()\n",
    "        return True\n",
    "    \n",
    "    def recognize_face(self, face_image, threshold=None):\n",
    "        \"\"\"Recognize a face against registered users using Euclidean distance\"\"\"\n",
    "        if threshold is None:\n",
    "            threshold = self.model_loader.threshold\n",
    "        \n",
    "        if not self.registered_users:\n",
    "            return None, 0.0\n",
    "        \n",
    "        # Get embedding for the input face\n",
    "        test_embedding = self.model_loader.get_embedding(face_image)\n",
    "        if test_embedding is None:\n",
    "            return None, 0.0\n",
    "        \n",
    "        best_match = None\n",
    "        best_distance = float('inf')\n",
    "        best_similarity = 0.0\n",
    "        \n",
    "        # Compare with all registered users using Euclidean distance\n",
    "        for user_name, embeddings in self.registered_users.items():\n",
    "            # Calculate distance with all embeddings for this user\n",
    "            distances = []\n",
    "            \n",
    "            for stored_embedding in embeddings:\n",
    "                # Calculate Euclidean distance (same as triplet loss uses)\n",
    "                distance = np.sqrt(np.sum((test_embedding - stored_embedding) ** 2))\n",
    "                distances.append(distance)\n",
    "            \n",
    "            # Use the minimum distance for this user (closest match)\n",
    "            min_distance = min(distances) if distances else float('inf')\n",
    "            \n",
    "            if min_distance < best_distance:\n",
    "                best_distance = min_distance\n",
    "                best_match = user_name\n",
    "                # Convert distance to similarity score\n",
    "                best_similarity = 1 / (1 + best_distance)\n",
    "        \n",
    "        # Apply threshold - for triplet loss, smaller distance means better match\n",
    "        if best_distance > threshold:\n",
    "            return None, best_similarity\n",
    "        \n",
    "        return best_match, best_similarity\n",
    "    \n",
    "    def _euclidean_distance(self, embedding1, embedding2):\n",
    "        \"\"\"Calculate Euclidean distance between two embeddings (for triplet loss)\"\"\"\n",
    "        return np.sqrt(np.sum((embedding1 - embedding2) ** 2))\n",
    "    \n",
    "    def list_registered_users(self):\n",
    "        \"\"\"List all registered users\"\"\"\n",
    "        if not self.registered_users:\n",
    "            print(\"üìù No users registered yet\")\n",
    "            return\n",
    "        \n",
    "        print(\"üìù Registered users:\")\n",
    "        for user_name, embeddings in self.registered_users.items():\n",
    "            print(f\"  - {user_name}: {len(embeddings)} face embeddings\")\n",
    "    \n",
    "    def remove_user(self, user_name):\n",
    "        \"\"\"Remove a registered user\"\"\"\n",
    "        if user_name in self.registered_users:\n",
    "            del self.registered_users[user_name]\n",
    "            if user_name in self.user_images:\n",
    "                del self.user_images[user_name]\n",
    "            self.save_registry()\n",
    "            print(f\"‚úÖ User {user_name} removed\")\n",
    "        else:\n",
    "            print(f\"‚ùå User {user_name} not found\")\n",
    "    \n",
    "    def save_registry(self):\n",
    "        \"\"\"Save user registry to file\"\"\"\n",
    "        try:\n",
    "            registry_data = {\n",
    "                'users': self.registered_users,\n",
    "                'images': self.user_images\n",
    "            }\n",
    "            with open(self.registry_file, 'wb') as f:\n",
    "                pickle.dump(registry_data, f)\n",
    "            print(f\"üíæ Registry saved to {self.registry_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving registry: {e}\")\n",
    "    \n",
    "    def load_registry(self):\n",
    "        \"\"\"Load user registry from file\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.registry_file):\n",
    "                with open(self.registry_file, 'rb') as f:\n",
    "                    registry_data = pickle.load(f)\n",
    "                self.registered_users = registry_data.get('users', {})\n",
    "                self.user_images = registry_data.get('images', {})\n",
    "                print(f\"üìÇ Registry loaded from {self.registry_file}\")\n",
    "                self.list_registered_users()\n",
    "            else:\n",
    "                print(\"üìù No existing registry found, starting fresh\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading registry: {e}\")\n",
    "            self.registered_users = {}\n",
    "            self.user_images = {}\n",
    "\n",
    "# Initialize user registry\n",
    "user_registry = UserFaceRegistry(model_loader, face_detector)\n",
    "\n",
    "# Helper functions for easy user registration\n",
    "def register_user_with_files(user_name):\n",
    "    \"\"\"Register user by selecting image files\"\"\"\n",
    "    print(f\"Please select one or more image files for {user_name}\")\n",
    "    \n",
    "    # Simple file selection (you might want to use tkinter for GUI)\n",
    "    image_paths = []\n",
    "    while True:\n",
    "        path = input(f\"Enter image path for {user_name} (or 'done' to finish): \").strip()\n",
    "        if path.lower() == 'done':\n",
    "            break\n",
    "        if os.path.exists(path):\n",
    "            image_paths.append(path)\n",
    "        else:\n",
    "            print(\"File not found, please try again\")\n",
    "    \n",
    "    if image_paths:\n",
    "        return user_registry.register_user_from_images(user_name, image_paths)\n",
    "    else:\n",
    "        print(\"No images provided\")\n",
    "        return False\n",
    "\n",
    "def register_user_with_camera(user_name, num_photos=5):\n",
    "    \"\"\"Register user using camera\"\"\"\n",
    "    return user_registry.register_user_from_camera(user_name, num_photos)\n",
    "\n",
    "print(\"üë• User face registration system ready for Triplet model!\")\n",
    "print(\"Use register_user_with_files('username') or register_user_with_camera('username') to register users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b617ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìπ Camera and video processing system ready!\n",
      "Use test_camera() to test your camera\n"
     ]
    }
   ],
   "source": [
    "# Camera Access and Video Processing\n",
    "\n",
    "class CameraManager:\n",
    "    \"\"\"Manage camera access and video processing\"\"\"\n",
    "    \n",
    "    def __init__(self, camera_index=0):\n",
    "        self.camera_index = camera_index\n",
    "        self.cap = None\n",
    "        self.is_running = False\n",
    "        self.frame_width = 640\n",
    "        self.frame_height = 480\n",
    "        self.fps = 30\n",
    "        \n",
    "    def initialize_camera(self):\n",
    "        \"\"\"Initialize camera with optimal settings\"\"\"\n",
    "        try:\n",
    "            self.cap = cv2.VideoCapture(self.camera_index)\n",
    "            \n",
    "            if not self.cap.isOpened():\n",
    "                print(f\"‚ùå Could not open camera {self.camera_index}\")\n",
    "                return False\n",
    "            \n",
    "            # Set camera properties for optimal performance\n",
    "            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.frame_width)\n",
    "            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.frame_height)\n",
    "            self.cap.set(cv2.CAP_PROP_FPS, self.fps)\n",
    "            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Reduce latency\n",
    "            \n",
    "            # Get actual settings\n",
    "            actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            actual_fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "            \n",
    "            print(f\"‚úÖ Camera initialized:\")\n",
    "            print(f\"   Resolution: {actual_width}x{actual_height}\")\n",
    "            print(f\"   FPS: {actual_fps}\")\n",
    "            \n",
    "            self.frame_width = actual_width\n",
    "            self.frame_height = actual_height\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error initializing camera: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def read_frame(self):\n",
    "        \"\"\"Read a frame from camera\"\"\"\n",
    "        if self.cap is None or not self.cap.isOpened():\n",
    "            return False, None\n",
    "        \n",
    "        ret, frame = self.cap.read()\n",
    "        return ret, frame\n",
    "    \n",
    "    def release_camera(self):\n",
    "        \"\"\"Release camera resources\"\"\"\n",
    "        if self.cap is not None:\n",
    "            self.cap.release()\n",
    "            self.cap = None\n",
    "            print(\"üì∑ Camera released\")\n",
    "    \n",
    "    def list_available_cameras(self):\n",
    "        \"\"\"List available cameras\"\"\"\n",
    "        available_cameras = []\n",
    "        \n",
    "        # Test camera indices 0-5\n",
    "        for i in range(6):\n",
    "            cap = cv2.VideoCapture(i)\n",
    "            if cap.isOpened():\n",
    "                available_cameras.append(i)\n",
    "                cap.release()\n",
    "        \n",
    "        if available_cameras:\n",
    "            print(f\"üìπ Available cameras: {available_cameras}\")\n",
    "        else:\n",
    "            print(\"‚ùå No cameras found\")\n",
    "        \n",
    "        return available_cameras\n",
    "    \n",
    "    def set_camera_settings(self, width=None, height=None, fps=None):\n",
    "        \"\"\"Update camera settings\"\"\"\n",
    "        if width:\n",
    "            self.frame_width = width\n",
    "        if height:\n",
    "            self.frame_height = height\n",
    "        if fps:\n",
    "            self.fps = fps\n",
    "        \n",
    "        if self.cap and self.cap.isOpened():\n",
    "            if width:\n",
    "                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "            if height:\n",
    "                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "            if fps:\n",
    "                self.cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "            \n",
    "            print(f\"üì∑ Camera settings updated\")\n",
    "\n",
    "class VideoProcessor:\n",
    "    \"\"\"Process video frames for face recognition\"\"\"\n",
    "    \n",
    "    def __init__(self, face_detector, user_registry):\n",
    "        self.face_detector = face_detector\n",
    "        self.user_registry = user_registry\n",
    "        self.recognition_threshold = 0.7\n",
    "        self.frame_skip = 2  # Process every nth frame for performance\n",
    "        self.frame_count = 0\n",
    "        \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process a single frame for face recognition\"\"\"\n",
    "        self.frame_count += 1\n",
    "        \n",
    "        # Skip frames for performance\n",
    "        if self.frame_count % self.frame_skip != 0:\n",
    "            return frame\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = self.face_detector.detect_faces(frame)\n",
    "        \n",
    "        # Process each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract face region\n",
    "            face_roi = self.face_detector.extract_face_roi(frame, (x, y, w, h))\n",
    "            \n",
    "            # Recognize face\n",
    "            user_name, confidence = self.user_registry.recognize_face(\n",
    "                face_roi, threshold=self.recognition_threshold\n",
    "            )\n",
    "            \n",
    "            # Draw bounding box\n",
    "            color = (0, 255, 0) if user_name else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            \n",
    "            # Draw label\n",
    "            if user_name:\n",
    "                label = f\"{user_name} ({confidence:.2f})\"\n",
    "                label_color = (0, 255, 0)\n",
    "            else:\n",
    "                label = f\"Unknown ({confidence:.2f})\"\n",
    "                label_color = (0, 0, 255)\n",
    "            \n",
    "            # Calculate text size for background\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(\n",
    "                label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2\n",
    "            )\n",
    "            \n",
    "            # Draw background rectangle for text\n",
    "            cv2.rectangle(\n",
    "                frame,\n",
    "                (x, y - text_height - 10),\n",
    "                (x + text_width, y),\n",
    "                label_color,\n",
    "                -1\n",
    "            )\n",
    "            \n",
    "            # Draw text\n",
    "            cv2.putText(\n",
    "                frame, label,\n",
    "                (x, y - 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6,\n",
    "                (255, 255, 255),\n",
    "                2\n",
    "            )\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def set_recognition_threshold(self, threshold):\n",
    "        \"\"\"Set recognition threshold\"\"\"\n",
    "        self.recognition_threshold = threshold\n",
    "        print(f\"üéØ Recognition threshold set to {threshold}\")\n",
    "    \n",
    "    def set_frame_skip(self, skip_frames):\n",
    "        \"\"\"Set frame skip for performance optimization\"\"\"\n",
    "        self.frame_skip = max(1, skip_frames)\n",
    "        print(f\"‚ö° Frame skip set to {skip_frames}\")\n",
    "\n",
    "# Initialize camera manager and video processor\n",
    "camera_manager = CameraManager()\n",
    "video_processor = VideoProcessor(face_detector, user_registry)\n",
    "\n",
    "# Camera testing function\n",
    "def test_camera():\n",
    "    \"\"\"Test camera functionality\"\"\"\n",
    "    print(\"üì∑ Testing camera...\")\n",
    "    \n",
    "    # List available cameras\n",
    "    camera_manager.list_available_cameras()\n",
    "    \n",
    "    # Initialize camera\n",
    "    if not camera_manager.initialize_camera():\n",
    "        return\n",
    "    \n",
    "    print(\"Press 'q' to quit camera test\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = camera_manager.read_frame()\n",
    "            \n",
    "            if not ret:\n",
    "                print(\"‚ùå Failed to read frame\")\n",
    "                break\n",
    "            \n",
    "            # Show frame\n",
    "            cv2.imshow('Camera Test', frame)\n",
    "            \n",
    "            # Break on 'q' key\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\\\n‚ö†Ô∏è Camera test interrupted\")\n",
    "    \n",
    "    finally:\n",
    "        camera_manager.release_camera()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    print(\"‚úÖ Camera test completed\")\n",
    "\n",
    "# Performance monitoring\n",
    "class PerformanceMonitor:\n",
    "    \"\"\"Monitor system performance during video processing\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fps_counter = 0\n",
    "        self.fps_start_time = time.time()\n",
    "        self.current_fps = 0\n",
    "        self.frame_times = []\n",
    "        self.max_frame_times = 30  # Keep last 30 frame times\n",
    "    \n",
    "    def update(self):\n",
    "        \"\"\"Update FPS counter\"\"\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Update frame times\n",
    "        if len(self.frame_times) > 0:\n",
    "            frame_time = current_time - self.frame_times[-1]\n",
    "            self.frame_times.append(current_time)\n",
    "            \n",
    "            if len(self.frame_times) > self.max_frame_times:\n",
    "                self.frame_times.pop(0)\n",
    "        else:\n",
    "            self.frame_times.append(current_time)\n",
    "        \n",
    "        # Update FPS every second\n",
    "        self.fps_counter += 1\n",
    "        elapsed = current_time - self.fps_start_time\n",
    "        \n",
    "        if elapsed >= 1.0:\n",
    "            self.current_fps = self.fps_counter / elapsed\n",
    "            self.fps_counter = 0\n",
    "            self.fps_start_time = current_time\n",
    "    \n",
    "    def get_fps(self):\n",
    "        \"\"\"Get current FPS\"\"\"\n",
    "        return self.current_fps\n",
    "    \n",
    "    def get_average_frame_time(self):\n",
    "        \"\"\"Get average frame processing time\"\"\"\n",
    "        if len(self.frame_times) < 2:\n",
    "            return 0\n",
    "        \n",
    "        total_time = self.frame_times[-1] - self.frame_times[0]\n",
    "        return total_time / (len(self.frame_times) - 1)\n",
    "    \n",
    "    def draw_stats(self, frame):\n",
    "        \"\"\"Draw performance stats on frame\"\"\"\n",
    "        stats_text = [\n",
    "            f\"FPS: {self.current_fps:.1f}\",\n",
    "            f\"Frame time: {self.get_average_frame_time()*1000:.1f}ms\"\n",
    "        ]\n",
    "        \n",
    "        y_offset = 30\n",
    "        for i, text in enumerate(stats_text):\n",
    "            y_pos = y_offset + (i * 30)\n",
    "            \n",
    "            # Draw background\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(\n",
    "                text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2\n",
    "            )\n",
    "            cv2.rectangle(frame, (10, y_pos - text_height - 5), \n",
    "                         (10 + text_width, y_pos + 5), (0, 0, 0), -1)\n",
    "            \n",
    "            # Draw text\n",
    "            cv2.putText(frame, text, (10, y_pos), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "# Initialize performance monitor\n",
    "performance_monitor = PerformanceMonitor()\n",
    "\n",
    "print(\"üìπ Camera and video processing system ready!\")\n",
    "print(\"Use test_camera() to test your camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ee0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time Face Recognition Pipeline\n",
    "\n",
    "class RealTimeFaceRecognizer:\n",
    "    \"\"\"Main class for real-time face recognition using Triplet model\"\"\"\n",
    "    \n",
    "    def __init__(self, model_loader, face_detector, user_registry, camera_manager):\n",
    "        self.model_loader = model_loader\n",
    "        self.face_detector = face_detector\n",
    "        self.user_registry = user_registry\n",
    "        self.camera_manager = camera_manager\n",
    "        self.performance_monitor = PerformanceMonitor()\n",
    "        \n",
    "        # Recognition settings - adjusted for triplet loss (distance-based)\n",
    "        self.recognition_threshold = 1.0  # Euclidean distance threshold\n",
    "        self.show_fps = True\n",
    "        self.show_confidence = True\n",
    "        self.save_screenshots = False\n",
    "        self.screenshot_dir = \"screenshots\"\n",
    "        \n",
    "        # Create screenshot directory if needed\n",
    "        if self.save_screenshots and not os.path.exists(self.screenshot_dir):\n",
    "            os.makedirs(self.screenshot_dir)\n",
    "    \n",
    "    def start_recognition(self):\n",
    "        \"\"\"Start real-time face recognition\"\"\"\n",
    "        if not self.model_loader.triplet_model:\n",
    "            print(\"‚ùå Triplet model not loaded. Please load a model first.\")\n",
    "            return\n",
    "        \n",
    "        if not self.user_registry.registered_users:\n",
    "            print(\"‚ö†Ô∏è No users registered. Register users first for recognition.\")\n",
    "            print(\"Starting in detection-only mode...\")\n",
    "        \n",
    "        # Initialize camera\n",
    "        if not self.camera_manager.initialize_camera():\n",
    "            return\n",
    "        \n",
    "        print(\"üé• Starting real-time face recognition with Triplet model...\")\n",
    "        print(\"Controls:\")\n",
    "        print(\"  'q' - Quit\")\n",
    "        print(\"  's' - Save screenshot\")\n",
    "        print(\"  'f' - Toggle FPS display\")\n",
    "        print(\"  '+' - Decrease recognition threshold (more lenient)\")\n",
    "        print(\"  '-' - Increase recognition threshold (more strict)\")\n",
    "        print(\"  'r' - Reset performance stats\")\n",
    "        print(f\"  Current threshold: {self.recognition_threshold:.2f} (lower = more lenient)\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # Read frame\n",
    "                ret, frame = self.camera_manager.read_frame()\n",
    "                if not ret:\n",
    "                    print(\"‚ùå Failed to read frame\")\n",
    "                    break\n",
    "                \n",
    "                # Update performance monitor\n",
    "                self.performance_monitor.update()\n",
    "                \n",
    "                # Process frame\n",
    "                processed_frame = self._process_frame(frame)\n",
    "                \n",
    "                # Add performance stats if enabled\n",
    "                if self.show_fps:\n",
    "                    self.performance_monitor.draw_stats(processed_frame)\n",
    "                \n",
    "                # Add instructions\n",
    "                self._draw_instructions(processed_frame)\n",
    "                \n",
    "                # Display frame\n",
    "                cv2.imshow('Real-Time Face Recognition (Triplet)', processed_frame)\n",
    "                \n",
    "                # Handle keyboard input\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('s'):\n",
    "                    self._save_screenshot(processed_frame)\n",
    "                elif key == ord('f'):\n",
    "                    self.show_fps = not self.show_fps\n",
    "                    print(f\"FPS display: {'ON' if self.show_fps else 'OFF'}\")\n",
    "                elif key == ord('+') or key == ord('='):\n",
    "                    # Decrease threshold (more lenient) for triplet loss\n",
    "                    self.recognition_threshold = max(0.1, self.recognition_threshold - 0.1)\n",
    "                    print(f\"Recognition threshold: {self.recognition_threshold:.2f} (more lenient)\")\n",
    "                elif key == ord('-'):\n",
    "                    # Increase threshold (more strict) for triplet loss\n",
    "                    self.recognition_threshold = min(3.0, self.recognition_threshold + 0.1)\n",
    "                    print(f\"Recognition threshold: {self.recognition_threshold:.2f} (more strict)\")\n",
    "                elif key == ord('r'):\n",
    "                    self.performance_monitor = PerformanceMonitor()\n",
    "                    print(\"Performance stats reset\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\\\n‚ö†Ô∏è Recognition interrupted by user\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during recognition: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        finally:\n",
    "            self.camera_manager.release_camera()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"‚úÖ Real-time recognition stopped\")\n",
    "    \n",
    "    def _process_frame(self, frame):\n",
    "        \"\"\"Process a single frame for face recognition\"\"\"\n",
    "        # Detect faces\n",
    "        faces = self.face_detector.detect_faces(frame)\n",
    "        \n",
    "        # Process each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract face region\n",
    "            face_roi = self.face_detector.extract_face_roi(frame, (x, y, w, h))\n",
    "            \n",
    "            # Recognize face if users are registered\n",
    "            if self.user_registry.registered_users:\n",
    "                user_name, similarity = self.user_registry.recognize_face(\n",
    "                    face_roi, threshold=self.recognition_threshold\n",
    "                )\n",
    "            else:\n",
    "                user_name, similarity = None, 0.0\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            self._draw_face_info(frame, (x, y, w, h), user_name, similarity)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def _draw_face_info(self, frame, face_rect, user_name, similarity):\n",
    "        \"\"\"Draw face bounding box and recognition info\"\"\"\n",
    "        x, y, w, h = face_rect\n",
    "        \n",
    "        # Choose colors based on recognition result\n",
    "        if user_name:\n",
    "            box_color = (0, 255, 0)  # Green for recognized\n",
    "            text_color = (0, 255, 0)\n",
    "            label = f\"{user_name}\"\n",
    "            if self.show_confidence:\n",
    "                label += f\" ({similarity:.2f})\"\n",
    "        else:\n",
    "            box_color = (0, 0, 255)  # Red for unknown\n",
    "            text_color = (0, 0, 255)\n",
    "            label = \"Unknown\"\n",
    "            if self.show_confidence:\n",
    "                label += f\" ({similarity:.2f})\"\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), box_color, 2)\n",
    "        \n",
    "        # Calculate text size for background\n",
    "        (text_width, text_height), baseline = cv2.getTextSize(\n",
    "            label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2\n",
    "        )\n",
    "        \n",
    "        # Draw background rectangle for text\n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (x, y - text_height - 10),\n",
    "            (x + text_width, y),\n",
    "            box_color,\n",
    "            -1\n",
    "        )\n",
    "        \n",
    "        # Draw text\n",
    "        cv2.putText(\n",
    "            frame, label,\n",
    "            (x, y - 5),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.7,\n",
    "            (255, 255, 255),\n",
    "            2\n",
    "        )\n",
    "        \n",
    "        # Draw confidence bar (adjusted for distance-based similarity)\n",
    "        if self.show_confidence:\n",
    "            bar_width = w\n",
    "            bar_height = 8\n",
    "            bar_x = x\n",
    "            bar_y = y + h + 5\n",
    "            \n",
    "            # Background bar\n",
    "            cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), \n",
    "                         (50, 50, 50), -1)\n",
    "            \n",
    "            # Confidence bar\n",
    "            conf_width = int(bar_width * similarity)\n",
    "            cv2.rectangle(frame, (bar_x, bar_y), (bar_x + conf_width, bar_y + bar_height), \n",
    "                         box_color, -1)\n",
    "    \n",
    "    def _draw_instructions(self, frame):\n",
    "        \"\"\"Draw control instructions on frame\"\"\"\n",
    "        instructions = [\n",
    "            \"Triplet Model | 'q'-Quit, 's'-Screenshot, 'f'-Toggle FPS\",\n",
    "            f\"Threshold: {self.recognition_threshold:.2f} ('+' less strict, '-' more strict)\"\n",
    "        ]\n",
    "        \n",
    "        # Draw semi-transparent background\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (10, frame.shape[0] - 60), \n",
    "                     (frame.shape[1] - 10, frame.shape[0] - 10), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "        \n",
    "        # Draw instructions\n",
    "        for i, instruction in enumerate(instructions):\n",
    "            y_pos = frame.shape[0] - 45 + (i * 20)\n",
    "            cv2.putText(frame, instruction, (15, y_pos), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    def _save_screenshot(self, frame):\n",
    "        \"\"\"Save screenshot with timestamp\"\"\"\n",
    "        if not os.path.exists(self.screenshot_dir):\n",
    "            os.makedirs(self.screenshot_dir)\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"{self.screenshot_dir}/screenshot_{timestamp}.jpg\"\n",
    "        \n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"üì∏ Screenshot saved: {filename}\")\n",
    "    \n",
    "    def set_recognition_threshold(self, threshold):\n",
    "        \"\"\"Set recognition threshold (distance for triplet loss)\"\"\"\n",
    "        self.recognition_threshold = max(0.1, min(3.0, threshold))\n",
    "        print(f\"üéØ Recognition threshold set to {self.recognition_threshold:.2f}\")\n",
    "    \n",
    "    def toggle_confidence_display(self):\n",
    "        \"\"\"Toggle confidence score display\"\"\"\n",
    "        self.show_confidence = not self.show_confidence\n",
    "        print(f\"Confidence display: {'ON' if self.show_confidence else 'OFF'}\")\n",
    "    \n",
    "    def enable_screenshot_saving(self, enable=True):\n",
    "        \"\"\"Enable or disable screenshot saving\"\"\"\n",
    "        self.save_screenshots = enable\n",
    "        if enable and not os.path.exists(self.screenshot_dir):\n",
    "            os.makedirs(self.screenshot_dir)\n",
    "        print(f\"Screenshot saving: {'ON' if enable else 'OFF'}\")\n",
    "\n",
    "# Initialize the main face recognition system\n",
    "recognizer = RealTimeFaceRecognizer(\n",
    "    model_loader=model_loader,\n",
    "    face_detector=face_detector,\n",
    "    user_registry=user_registry,\n",
    "    camera_manager=camera_manager\n",
    ")\n",
    "\n",
    "# Quick setup function\n",
    "def quick_setup():\n",
    "    \"\"\"Quick setup for face recognition system\"\"\"\n",
    "    print(\"üöÄ Quick Setup for Real-Time Face Recognition (Triplet Model)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check model\n",
    "    if not model_loader.triplet_model:\n",
    "        print(\"‚ùå No triplet model loaded. Please load a model first.\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"‚úÖ Triplet model loaded\")\n",
    "        if model_loader.base_network:\n",
    "            print(\"‚úÖ Base network extracted for embeddings\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Base network extraction may have issues\")\n",
    "    \n",
    "    # Check camera\n",
    "    available_cameras = camera_manager.list_available_cameras()\n",
    "    if not available_cameras:\n",
    "        print(\"‚ùå No cameras available\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"‚úÖ Camera available\")\n",
    "    \n",
    "    # Check registered users\n",
    "    if not user_registry.registered_users:\n",
    "        print(\"‚ö†Ô∏è No users registered\")\n",
    "        print(\"The system will run in detection-only mode\")\n",
    "        print(\"Use register_user_with_camera('username') to register users\")\n",
    "    else:\n",
    "        print(f\"‚úÖ {len(user_registry.registered_users)} users registered\")\n",
    "        user_registry.list_registered_users()\n",
    "    \n",
    "    print(f\"\\\\nüéØ Current recognition threshold: {recognizer.recognition_threshold:.2f}\")\n",
    "    print(\"   (Lower threshold = more lenient matching)\")\n",
    "    print(\"\\\\nüé• Ready to start real-time face recognition!\")\n",
    "    print(\"Use recognizer.start_recognition() to begin\")\n",
    "    return True\n",
    "\n",
    "# Main function to start everything\n",
    "def start_face_recognition():\n",
    "    \"\"\"Start the complete face recognition system\"\"\"\n",
    "    print(\"üé¨ Starting Real-Time Face Recognition System (Triplet Model)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if quick_setup():\n",
    "        print(\"\\\\nStarting recognition in 3 seconds...\")\n",
    "        time.sleep(3)\n",
    "        recognizer.start_recognition()\n",
    "    else:\n",
    "        print(\"‚ùå Setup failed. Please resolve the issues above.\")\n",
    "\n",
    "print(\"üéØ Real-time face recognition pipeline ready for Triplet model!\")\n",
    "print(\"Use start_face_recognition() to start the complete system\")\n",
    "print(\"Or use recognizer.start_recognition() to start recognition directly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e178111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Monitoring and Results Display\n",
    "\n",
    "class AdvancedPerformanceMonitor:\n",
    "    \"\"\"Advanced performance monitoring with detailed metrics\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fps_history = []\n",
    "        self.recognition_times = []\n",
    "        self.detection_times = []\n",
    "        self.total_frames = 0\n",
    "        self.recognized_faces = 0\n",
    "        self.unknown_faces = 0\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Performance thresholds\n",
    "        self.target_fps = 30\n",
    "        self.warning_fps = 15\n",
    "        \n",
    "    def log_frame(self, fps, detection_time=None, recognition_time=None, faces_detected=0, faces_recognized=0):\n",
    "        \"\"\"Log frame processing metrics\"\"\"\n",
    "        self.total_frames += 1\n",
    "        self.fps_history.append(fps)\n",
    "        \n",
    "        if detection_time:\n",
    "            self.detection_times.append(detection_time)\n",
    "        \n",
    "        if recognition_time:\n",
    "            self.recognition_times.append(recognition_time)\n",
    "        \n",
    "        self.recognized_faces += faces_recognized\n",
    "        self.unknown_faces += (faces_detected - faces_recognized)\n",
    "        \n",
    "        # Keep only last 100 measurements\n",
    "        if len(self.fps_history) > 100:\n",
    "            self.fps_history.pop(0)\n",
    "        if len(self.detection_times) > 100:\n",
    "            self.detection_times.pop(0)\n",
    "        if len(self.recognition_times) > 100:\n",
    "            self.recognition_times.pop(0)\n",
    "    \n",
    "    def get_performance_stats(self):\n",
    "        \"\"\"Get comprehensive performance statistics\"\"\"\n",
    "        current_time = time.time()\n",
    "        runtime = current_time - self.start_time\n",
    "        \n",
    "        stats = {\n",
    "            'runtime_seconds': runtime,\n",
    "            'total_frames': self.total_frames,\n",
    "            'average_fps': np.mean(self.fps_history) if self.fps_history else 0,\n",
    "            'current_fps': self.fps_history[-1] if self.fps_history else 0,\n",
    "            'min_fps': np.min(self.fps_history) if self.fps_history else 0,\n",
    "            'max_fps': np.max(self.fps_history) if self.fps_history else 0,\n",
    "            'avg_detection_time': np.mean(self.detection_times) if self.detection_times else 0,\n",
    "            'avg_recognition_time': np.mean(self.recognition_times) if self.recognition_times else 0,\n",
    "            'total_faces_detected': self.recognized_faces + self.unknown_faces,\n",
    "            'faces_recognized': self.recognized_faces,\n",
    "            'faces_unknown': self.unknown_faces,\n",
    "            'recognition_rate': self.recognized_faces / max(1, self.recognized_faces + self.unknown_faces)\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def get_performance_status(self):\n",
    "        \"\"\"Get performance status (Good, Warning, Poor)\"\"\"\n",
    "        if not self.fps_history:\n",
    "            return \"Unknown\"\n",
    "        \n",
    "        current_fps = self.fps_history[-1]\n",
    "        \n",
    "        if current_fps >= self.target_fps:\n",
    "            return \"Excellent\"\n",
    "        elif current_fps >= self.warning_fps:\n",
    "            return \"Good\"\n",
    "        elif current_fps >= 10:\n",
    "            return \"Warning\"\n",
    "        else:\n",
    "            return \"Poor\"\n",
    "    \n",
    "    def print_performance_report(self):\n",
    "        \"\"\"Print detailed performance report\"\"\"\n",
    "        stats = self.get_performance_stats()\n",
    "        status = self.get_performance_status()\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\" * 60)\n",
    "        print(\"üìä PERFORMANCE REPORT (Triplet Model)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"‚è±Ô∏è  Runtime: {stats['runtime_seconds']:.1f} seconds\")\n",
    "        print(f\"üé¨ Total Frames: {stats['total_frames']}\")\n",
    "        print(f\"üìà Performance Status: {status}\")\n",
    "        \n",
    "        print(\"\\\\nFPS Metrics:\")\n",
    "        print(f\"  Current FPS: {stats['current_fps']:.1f}\")\n",
    "        print(f\"  Average FPS: {stats['average_fps']:.1f}\")\n",
    "        print(f\"  Min FPS: {stats['min_fps']:.1f}\")\n",
    "        print(f\"  Max FPS: {stats['max_fps']:.1f}\")\n",
    "        \n",
    "        print(\"\\\\nProcessing Times:\")\n",
    "        print(f\"  Avg Detection Time: {stats['avg_detection_time']*1000:.1f}ms\")\n",
    "        print(f\"  Avg Recognition Time: {stats['avg_recognition_time']*1000:.1f}ms\")\n",
    "        \n",
    "        print(\"\\\\nRecognition Stats:\")\n",
    "        print(f\"  Total Faces Detected: {stats['total_faces_detected']}\")\n",
    "        print(f\"  Faces Recognized: {stats['faces_recognized']}\")\n",
    "        print(f\"  Unknown Faces: {stats['faces_unknown']}\")\n",
    "        print(f\"  Recognition Rate: {stats['recognition_rate']*100:.1f}%\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    def plot_performance_graphs(self):\n",
    "        \"\"\"Plot performance graphs\"\"\"\n",
    "        if len(self.fps_history) < 2:\n",
    "            print(\"Not enough data for plotting\")\n",
    "            return\n",
    "        \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # FPS over time\n",
    "        ax1.plot(self.fps_history, color='blue', linewidth=2)\n",
    "        ax1.axhline(y=self.target_fps, color='green', linestyle='--', label=f'Target ({self.target_fps} FPS)')\n",
    "        ax1.axhline(y=self.warning_fps, color='orange', linestyle='--', label=f'Warning ({self.warning_fps} FPS)')\n",
    "        ax1.set_title('FPS Over Time (Triplet Model)', fontweight='bold')\n",
    "        ax1.set_xlabel('Frame Number')\n",
    "        ax1.set_ylabel('FPS')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # FPS histogram\n",
    "        ax2.hist(self.fps_history, bins=20, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "        ax2.axvline(x=np.mean(self.fps_history), color='red', linestyle='--', \n",
    "                   label=f'Mean: {np.mean(self.fps_history):.1f}')\n",
    "        ax2.set_title('FPS Distribution', fontweight='bold')\n",
    "        ax2.set_xlabel('FPS')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Processing times\n",
    "        if self.detection_times and self.recognition_times:\n",
    "            ax3.plot([t*1000 for t in self.detection_times], label='Detection', color='green')\n",
    "            ax3.plot([t*1000 for t in self.recognition_times], label='Recognition', color='red')\n",
    "            ax3.set_title('Processing Times', fontweight='bold')\n",
    "            ax3.set_xlabel('Frame Number')\n",
    "            ax3.set_ylabel('Time (ms)')\n",
    "            ax3.legend()\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Recognition statistics pie chart\n",
    "        recognition_data = [self.recognized_faces, self.unknown_faces]\n",
    "        recognition_labels = ['Recognized', 'Unknown']\n",
    "        recognition_colors = ['lightgreen', 'lightcoral']\n",
    "        \n",
    "        ax4.pie(recognition_data, labels=recognition_labels, colors=recognition_colors, \n",
    "               autopct='%1.1f%%', startangle=90)\n",
    "        ax4.set_title('Face Recognition Results', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "class SystemDiagnostics:\n",
    "    \"\"\"System diagnostics and troubleshooting\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_system_requirements():\n",
    "        \"\"\"Check if system meets requirements\"\"\"\n",
    "        print(\"üîç System Requirements Check\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Check Python version\n",
    "        import sys\n",
    "        python_version = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "        print(f\"Python Version: {python_version}\")\n",
    "        \n",
    "        # Check TensorFlow\n",
    "        print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "        \n",
    "        # Check OpenCV\n",
    "        print(f\"OpenCV Version: {cv2.__version__}\")\n",
    "        \n",
    "        # Check GPU availability\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        print(f\"GPU Available: {'Yes' if gpus else 'No'}\")\n",
    "        if gpus:\n",
    "            for gpu in gpus:\n",
    "                print(f\"  - {gpu}\")\n",
    "        \n",
    "        # Check memory\n",
    "        try:\n",
    "            import psutil\n",
    "            memory = psutil.virtual_memory()\n",
    "            print(f\"Total RAM: {memory.total / (1024**3):.1f} GB\")\n",
    "            print(f\"Available RAM: {memory.available / (1024**3):.1f} GB\")\n",
    "        except ImportError:\n",
    "            print(\"psutil not available - cannot check memory\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    @staticmethod\n",
    "    def test_model_performance(model_loader, test_image_path=None):\n",
    "        \"\"\"Test triplet model inference performance\"\"\"\n",
    "        if not model_loader.triplet_model:\n",
    "            print(\"‚ùå No triplet model loaded\")\n",
    "            return\n",
    "        \n",
    "        print(\"üß™ Testing Triplet Model Performance\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Create dummy test image if no path provided\n",
    "        if test_image_path is None or not os.path.exists(test_image_path):\n",
    "            test_image = np.random.randint(0, 256, (*IMG_SIZE, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            test_image = cv2.imread(test_image_path)\n",
    "            test_image = cv2.resize(test_image, IMG_SIZE)\n",
    "        \n",
    "        # Test embedding extraction\n",
    "        start_time = time.time()\n",
    "        for i in range(10):\n",
    "            embedding = model_loader.get_embedding(test_image)\n",
    "        embedding_time = (time.time() - start_time) / 10\n",
    "        \n",
    "        print(f\"Average Embedding Time: {embedding_time*1000:.1f}ms\")\n",
    "        \n",
    "        # Test face comparison\n",
    "        start_time = time.time()\n",
    "        for i in range(10):\n",
    "            similarity, is_match = model_loader.compare_faces(test_image, test_image)\n",
    "        comparison_time = (time.time() - start_time) / 10\n",
    "        \n",
    "        print(f\"Average Comparison Time: {comparison_time*1000:.1f}ms\")\n",
    "        print(f\"Embedding Shape: {embedding.shape if embedding is not None else 'N/A'}\")\n",
    "        print(f\"Self-comparison similarity: {similarity:.3f}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    @staticmethod\n",
    "    def benchmark_face_detection(face_detector, camera_manager, duration=10):\n",
    "        \"\"\"Benchmark face detection performance\"\"\"\n",
    "        print(f\"üéØ Benchmarking Face Detection ({duration}s)\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        if not camera_manager.initialize_camera():\n",
    "            print(\"‚ùå Cannot initialize camera for benchmark\")\n",
    "            return\n",
    "        \n",
    "        frame_count = 0\n",
    "        total_faces = 0\n",
    "        total_detection_time = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            while time.time() - start_time < duration:\n",
    "                ret, frame = camera_manager.read_frame()\n",
    "                if not ret:\n",
    "                    continue\n",
    "                \n",
    "                # Time face detection\n",
    "                det_start = time.time()\n",
    "                faces = face_detector.detect_faces(frame)\n",
    "                det_time = time.time() - det_start\n",
    "                \n",
    "                frame_count += 1\n",
    "                total_faces += len(faces)\n",
    "                total_detection_time += det_time\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "        \n",
    "        finally:\n",
    "            camera_manager.release_camera()\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        avg_fps = frame_count / elapsed\n",
    "        avg_detection_time = total_detection_time / frame_count if frame_count > 0 else 0\n",
    "        avg_faces_per_frame = total_faces / frame_count if frame_count > 0 else 0\n",
    "        \n",
    "        print(f\"Frames Processed: {frame_count}\")\n",
    "        print(f\"Average FPS: {avg_fps:.1f}\")\n",
    "        print(f\"Average Detection Time: {avg_detection_time*1000:.1f}ms\")\n",
    "        print(f\"Average Faces per Frame: {avg_faces_per_frame:.1f}\")\n",
    "        print(f\"Total Faces Detected: {total_faces}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Usage examples and helper functions\n",
    "def run_complete_system_test():\n",
    "    \"\"\"Run complete system test\"\"\"\n",
    "    print(\"üß™ Running Complete System Test (Triplet Model)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # System requirements\n",
    "    SystemDiagnostics.check_system_requirements()\n",
    "    \n",
    "    # Model performance\n",
    "    SystemDiagnostics.test_model_performance(model_loader)\n",
    "    \n",
    "    # Face detection benchmark\n",
    "    SystemDiagnostics.benchmark_face_detection(face_detector, camera_manager, duration=5)\n",
    "    \n",
    "    print(\"‚úÖ System test completed\")\n",
    "\n",
    "def test_triplet_model_loading():\n",
    "    \"\"\"Test if triplet model is properly loaded\"\"\"\n",
    "    print(\"üß™ Testing Triplet Model Loading\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if not model_loader.triplet_model:\n",
    "        print(\"‚ùå Triplet model not loaded\")\n",
    "        return False\n",
    "    \n",
    "    print(\"‚úÖ Triplet model loaded successfully\")\n",
    "    print(f\"Model type: {type(model_loader.triplet_model)}\")\n",
    "    print(f\"Input shape: {model_loader.triplet_model.input_shape}\")\n",
    "    print(f\"Output shape: {model_loader.triplet_model.output_shape}\")\n",
    "    \n",
    "    if model_loader.base_network:\n",
    "        print(\"‚úÖ Base network extracted\")\n",
    "        print(f\"Base network type: {type(model_loader.base_network)}\")\n",
    "        print(f\"Base network output shape: {model_loader.base_network.output_shape}\")\n",
    "    else:\n",
    "        print(\"‚ùå Base network not available\")\n",
    "        return False\n",
    "    \n",
    "    # Test with dummy data\n",
    "    try:\n",
    "        dummy_image = np.random.randint(0, 256, (*IMG_SIZE, 3), dtype=np.uint8)\n",
    "        embedding = model_loader.get_embedding(dummy_image)\n",
    "        \n",
    "        if embedding is not None:\n",
    "            print(f\"‚úÖ Embedding extraction working - shape: {embedding.shape}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå Embedding extraction failed\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing embedding extraction: {e}\")\n",
    "        return False\n",
    "\n",
    "def quick_demo():\n",
    "    \"\"\"Quick demonstration of the system\"\"\"\n",
    "    print(\"üé¨ Quick Demo Mode (Triplet Model)\")\n",
    "    print(\"This will run face recognition for 30 seconds\")\n",
    "    \n",
    "    if not model_loader.triplet_model:\n",
    "        print(\"‚ùå Triplet model not loaded\")\n",
    "        return\n",
    "    \n",
    "    # Test model first\n",
    "    if not test_triplet_model_loading():\n",
    "        print(\"‚ùå Model testing failed\")\n",
    "        return\n",
    "    \n",
    "    # Temporarily modify recognizer for demo\n",
    "    original_instructions = recognizer._draw_instructions\n",
    "    \n",
    "    def demo_instructions(frame):\n",
    "        demo_text = [\n",
    "            \"DEMO MODE - Triplet Model - 30 second test\",\n",
    "            \"System will stop automatically\"\n",
    "        ]\n",
    "        \n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (10, 10), (450, 70), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "        \n",
    "        for i, text in enumerate(demo_text):\n",
    "            y_pos = 35 + (i * 20)\n",
    "            cv2.putText(frame, text, (15, y_pos), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "    \n",
    "    recognizer._draw_instructions = demo_instructions\n",
    "    \n",
    "    # Start demo\n",
    "    demo_monitor = AdvancedPerformanceMonitor()\n",
    "    \n",
    "    if camera_manager.initialize_camera():\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            while time.time() - start_time < 30:\n",
    "                ret, frame = camera_manager.read_frame()\n",
    "                if not ret:\n",
    "                    continue\n",
    "                \n",
    "                processed_frame = recognizer._process_frame(frame)\n",
    "                demo_instructions(processed_frame)\n",
    "                \n",
    "                if recognizer.show_fps:\n",
    "                    performance_monitor.draw_stats(processed_frame)\n",
    "                \n",
    "                cv2.imshow('Quick Demo - Triplet Model', processed_frame)\n",
    "                \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Demo error: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            camera_manager.release_camera()\n",
    "            cv2.destroyAllWindows()\n",
    "    \n",
    "    # Restore original function\n",
    "    recognizer._draw_instructions = original_instructions\n",
    "    \n",
    "    print(\"‚úÖ Demo completed\")\n",
    "\n",
    "# Initialize advanced performance monitor\n",
    "advanced_monitor = AdvancedPerformanceMonitor()\n",
    "\n",
    "print(\"üìä Performance monitoring and diagnostics ready for Triplet model!\")\n",
    "print(\"Available functions:\")\n",
    "print(\"- test_triplet_model_loading(): Test if triplet model loads correctly\")\n",
    "print(\"- run_complete_system_test(): Test all system components\")\n",
    "print(\"- quick_demo(): 30-second demonstration\")\n",
    "print(\"- advanced_monitor.print_performance_report(): Detailed performance report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982f644",
   "metadata": {},
   "source": [
    "# üöÄ Usage Guide and Examples\n",
    "\n",
    "## Quick Start Guide\n",
    "\n",
    "### 1. **Load Your Trained Model**\n",
    "The notebook will automatically try to load your saved Siamese model. Make sure one of these files exists in your directory:\n",
    "- `best_improved_siamese_model.h5`\n",
    "- `improved_siamese_deployment.h5` \n",
    "- `siamese_model.h5`\n",
    "\n",
    "### 2. **Register Users**\n",
    "You can register users in two ways:\n",
    "\n",
    "**From Camera (Recommended):**\n",
    "```python\n",
    "# Register a user by taking 5 photos with the camera\n",
    "register_user_with_camera(\"John\", num_photos=5)\n",
    "```\n",
    "\n",
    "**From Image Files:**\n",
    "```python\n",
    "# Register a user from existing image files\n",
    "register_user_with_files(\"Jane\")\n",
    "# Then enter image paths when prompted\n",
    "```\n",
    "\n",
    "### 3. **Start Real-Time Recognition**\n",
    "```python\n",
    "# Start the complete system with automatic setup\n",
    "start_face_recognition()\n",
    "\n",
    "# Or start recognition directly\n",
    "recognizer.start_recognition()\n",
    "```\n",
    "\n",
    "## üéõÔ∏è Controls During Recognition\n",
    "\n",
    "| Key | Action |\n",
    "|-----|--------|\n",
    "| `q` | Quit the application |\n",
    "| `s` | Save screenshot |\n",
    "| `f` | Toggle FPS display |\n",
    "| `+/=` | Increase recognition threshold |\n",
    "| `-` | Decrease recognition threshold |\n",
    "| `r` | Reset performance statistics |\n",
    "\n",
    "## ‚öôÔ∏è Configuration Options\n",
    "\n",
    "### Adjust Recognition Sensitivity\n",
    "```python\n",
    "# More strict (fewer false positives)\n",
    "recognizer.set_recognition_threshold(0.8)\n",
    "\n",
    "# More lenient (fewer false negatives)  \n",
    "recognizer.set_recognition_threshold(0.4)\n",
    "```\n",
    "\n",
    "### Change Camera Settings\n",
    "```python\n",
    "# List available cameras\n",
    "camera_manager.list_available_cameras()\n",
    "\n",
    "# Use different camera\n",
    "camera_manager.camera_index = 1\n",
    "\n",
    "# Adjust resolution for performance\n",
    "camera_manager.set_camera_settings(width=320, height=240)\n",
    "```\n",
    "\n",
    "## üîß System Testing\n",
    "\n",
    "### Test Individual Components\n",
    "```python\n",
    "# Test camera\n",
    "test_camera()\n",
    "\n",
    "# Test face detection\n",
    "test_face_detection()\n",
    "\n",
    "# Run complete system diagnostics\n",
    "run_complete_system_test()\n",
    "\n",
    "# Quick 30-second demo\n",
    "quick_demo()\n",
    "```\n",
    "\n",
    "### Performance Monitoring\n",
    "```python\n",
    "# Print detailed performance report\n",
    "advanced_monitor.print_performance_report()\n",
    "\n",
    "# Plot performance graphs\n",
    "advanced_monitor.plot_performance_graphs()\n",
    "```\n",
    "\n",
    "## üìù User Management\n",
    "\n",
    "### List Registered Users\n",
    "```python\n",
    "user_registry.list_registered_users()\n",
    "```\n",
    "\n",
    "### Remove a User\n",
    "```python\n",
    "user_registry.remove_user(\"username\")\n",
    "```\n",
    "\n",
    "### Check Recognition Statistics\n",
    "```python\n",
    "# View recognition stats\n",
    "stats = advanced_monitor.get_performance_stats()\n",
    "print(f\"Recognition rate: {stats['recognition_rate']*100:.1f}%\")\n",
    "```\n",
    "\n",
    "## üîç Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "**1. Model Not Loading**\n",
    "- Ensure your model file exists in the current directory\n",
    "- Check that the model was saved with the correct custom objects\n",
    "\n",
    "**2. Camera Not Working**\n",
    "- Check if camera is being used by another application\n",
    "- Try different camera indices (0, 1, 2...)\n",
    "- Verify camera permissions\n",
    "\n",
    "**3. Poor Recognition Performance**\n",
    "- Adjust recognition threshold (lower = more lenient)\n",
    "- Ensure good lighting conditions\n",
    "- Register multiple photos per user\n",
    "- Check if users' faces are clearly visible\n",
    "\n",
    "**4. Low FPS Performance**\n",
    "- Reduce camera resolution\n",
    "- Skip more frames for processing\n",
    "- Use GPU acceleration if available\n",
    "\n",
    "### System Requirements Check\n",
    "```python\n",
    "SystemDiagnostics.check_system_requirements()\n",
    "```\n",
    "\n",
    "## üéØ Best Practices\n",
    "\n",
    "### For Better Recognition Accuracy:\n",
    "1. **Register multiple photos** per user (3-5 recommended)\n",
    "2. **Use good lighting** when registering and recognizing\n",
    "3. **Face the camera directly** during registration\n",
    "4. **Avoid extreme expressions** during registration\n",
    "5. **Register in similar conditions** to where recognition will be used\n",
    "\n",
    "### For Better Performance:\n",
    "1. **Use appropriate resolution** (640x480 is usually sufficient)\n",
    "2. **Adjust frame skip** for lower-end hardware\n",
    "3. **Close other applications** that might use camera/GPU\n",
    "4. **Use GPU acceleration** when available\n",
    "\n",
    "## üìä Example Workflow\n",
    "\n",
    "```python\n",
    "# 1. Load model (automatic)\n",
    "print(\"Model loaded:\", model_loaded)\n",
    "\n",
    "# 2. Register users\n",
    "register_user_with_camera(\"Alice\", num_photos=5)\n",
    "register_user_with_camera(\"Bob\", num_photos=5)\n",
    "\n",
    "# 3. Check registrations\n",
    "user_registry.list_registered_users()\n",
    "\n",
    "# 4. Test system\n",
    "quick_demo()\n",
    "\n",
    "# 5. Start full recognition\n",
    "start_face_recognition()\n",
    "\n",
    "# 6. After use, check performance\n",
    "advanced_monitor.print_performance_report()\n",
    "```\n",
    "\n",
    "This system provides a complete solution for real-time face recognition using your trained Siamese network!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
